program: train_sac_parallel.py
method: bayes
metric:
  name: eval/mean_reward  
  goal: maximize

parameters:
  # --- Fixed Parameters ---
  total_timesteps:
    value: 2000000
  eval_freq:
    value: 20000
  opponent:
    value: mix
  
  # Set the path to your best model here (optional, triggers mixed opponents)
  opponent_model:
     value: "checkpoints/sac_hockey_best_strong_killer.pth"

  # --- Hyperparameters to Tune ---
  batch_size:
    values: [512, 1024, 2048]

  hidden_size:
    values: [256, 512]

  actor_learning_rate:
    distribution: log_uniform_values
    min: 0.0001
    max: 0.001

  critic_learning_rate:
    distribution: log_uniform_values
    min: 0.0001
    max: 0.001

  alpha_learning_rate:
    distribution: log_uniform_values
    min: 0.00001
    max: 0.0001

  tau:
    values: [0.005, 0.01, 0.02]

  gamma:
    values: [0.99, 0.995]

  alpha:
    values: [0.1, 0.2, 0.05]

command:
  - ${env}
  - python
  - ${program}
  - ${args}
  - "--wandb"