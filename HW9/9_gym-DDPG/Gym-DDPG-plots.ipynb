{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-06-19T21:24:03.206035Z",
     "start_time": "2023-06-19T21:24:02.792104Z"
    }
   },
   "outputs": [],
   "source": [
    "import gymnasium as gym\n",
    "from gymnasium import spaces\n",
    "import numpy as np\n",
    "import pickle\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "from matplotlib import cm\n",
    "import pylab as plt\n",
    "\n",
    "import DDPG\n",
    "import torch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Helper Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-06-19T21:24:03.211465Z",
     "start_time": "2023-06-19T21:24:03.208324Z"
    }
   },
   "outputs": [],
   "source": [
    "def running_mean(x, N):\n",
    "    cumsum = np.cumsum(np.insert(x, 0, 0)) \n",
    "    return (cumsum[N:] - cumsum[:-N]) / float(N)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run(env, agent, n_episodes=100, noise=0):\n",
    "    rewards = []\n",
    "    observations = []\n",
    "    actions = []\n",
    "    for ep in range(1, n_episodes+1):\n",
    "        ep_reward = 0\n",
    "        state, _info = env.reset()\n",
    "        for t in range(2000):\n",
    "            action = agent.act(state, noise)\n",
    "            state, reward, done, _trunc, _info = env.step(action)\n",
    "            observations.append(state)\n",
    "            actions.append(action)\n",
    "            ep_reward += reward\n",
    "            if done or _trunc:\n",
    "                break\n",
    "        rewards.append(ep_reward)\n",
    "        ep_reward = 0\n",
    "    print(f'Mean reward: {np.mean(rewards)}')\n",
    "    observations = np.asarray(observations)\n",
    "    actions = np.asarray(actions)\n",
    "    return observations, actions, rewards"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DDPG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-06-20T05:28:44.820757Z",
     "start_time": "2023-06-20T05:28:44.737773Z"
    }
   },
   "outputs": [],
   "source": [
    "env_name = \"Pendulum-v1\"\n",
    "\n",
    "eps=0.1\n",
    "ts=32\n",
    "lr=0.0001\n",
    "s=1\n",
    "\n",
    "with open(f\"./results/DDPG_{env_name}-eps{eps}-t{ts}-l{lr}-s{s}-stat.pkl\", 'rb') as f:\n",
    "    data = pickle.load(f)\n",
    "    rewards = np.asarray(data[\"rewards\"])\n",
    "    losses =  np.asarray(data[\"losses\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-06-20T05:28:46.754291Z",
     "start_time": "2023-06-20T05:28:46.477579Z"
    }
   },
   "outputs": [],
   "source": [
    "fig=plt.figure(figsize=(6,3.8))\n",
    "plt.plot(running_mean(losses[:,0],10),label=f\"Q loss\")\n",
    "plt.plot(running_mean(losses[:,1],10),label=f\"pi loss\")\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TODO: Plot the rewards and the dependency on the hyperparameters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-06-17T20:37:14.693823Z",
     "start_time": "2023-06-17T20:37:14.688866Z"
    }
   },
   "source": [
    "## value function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-06-20T05:29:17.636280Z",
     "start_time": "2023-06-20T05:29:17.627434Z"
    }
   },
   "outputs": [],
   "source": [
    "def plot_Q_function(q_function, observations, actions, plot_dim1=0, plot_dim2=2,\n",
    "                    label_dim1=\"cos(angle)\", label_dim2=\"angular velocity\"):\n",
    "    plt.rcParams.update({'font.size': 12})\n",
    "    values =q_function.predict(np.hstack([observations,actions]))\n",
    "    \n",
    "    fig = plt.figure(figsize=[10,8])\n",
    "    ax = fig.add_subplot()\n",
    "    surf = ax.scatter (observations[:,plot_dim1], observations[:,plot_dim2],  c = values, cmap=cm.coolwarm)\n",
    "    ax.set_xlabel(label_dim1)\n",
    "    ax.set_ylabel(label_dim2)\n",
    "\n",
    "    return fig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-06-20T05:29:18.142221Z",
     "start_time": "2023-06-20T05:29:18.127914Z"
    }
   },
   "outputs": [],
   "source": [
    "env = gym.make(env_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-06-20T05:29:44.407216Z",
     "start_time": "2023-06-20T05:29:44.402306Z"
    }
   },
   "outputs": [],
   "source": [
    "episodes=2000\n",
    "eps=0.1\n",
    "ts=32\n",
    "lr=0.0001\n",
    "checkpoint = f\"./results/DDPG_{env_name}_{episodes}-eps{eps}-t{ts}-l{lr}-s1.pth\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TODO: \n",
    "\n",
    "Initialize the DDPGAgent and load the checkpoint \n",
    "\n",
    "run 100 runs with noise 0.2 (see run function)\n",
    "\n",
    "use the helper function above to plot the Q function"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Bonus: Have we done the right thing? We run the policy with noise to see different states. Are the Q-values actually correct? Can you fix it?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## HalfCheetah"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Gym-RL",
   "language": "python",
   "name": "gym-rl"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
